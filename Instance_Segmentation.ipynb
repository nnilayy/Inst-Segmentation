{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLG7rVNlIBmz5qSUbT5bwo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/Instance-Segmentation/blob/main/Instance_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check nvcc version\n",
        "!nvcc --version\n",
        "# Check GCC version\n",
        "!gcc --version  \n",
        "# Check graphics card version \n",
        "!nvidia-smi  "
      ],
      "metadata": {
        "id": "Vc87CE6zROLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "import mmdet\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(\"Torch Version: \",torch.__version__) \n",
        "print(\"mmdet Verion: \",mmdet.__version__)\n",
        "print(\"Is Cuda Available: \",torch.cuda.is_available()) \n",
        "print(\"Cuda Version: \",get_compiling_cuda_version())\n",
        "print(\"GCC version: \",get_compiler_version())"
      ],
      "metadata": {
        "id": "xZbPWw--RQ3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "npzHQtngal9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##INSTALL MMCV AND MMDETECTION"
      ],
      "metadata": {
        "id": "xt9RBe9x-EKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install mmcv\n",
        "!pip install openmim\n",
        "!mim install mmcv-full\n",
        "\n",
        "# install mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "ZYl2TfdBROP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DOWNLOADING THE DATASET"
      ],
      "metadata": {
        "id": "gybKKR--Mm3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download and unzip the data\n",
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n",
        "!unzip balloon_dataset.zip > /dev/null"
      ],
      "metadata": {
        "id": "Y6z76RxORe_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at the dataset image\n",
        "import mmcv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = mmcv.imread('balloon/train/10464445726_6f1e3bbe6a_k.jpg')\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(mmcv.bgr2rgb(img))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q5Fks2piRkXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carafe\n",
        "link=\"https://download.openmmlab.com/mmdetection/v2.0/carafe/mask_rcnn_r50_fpn_carafe_1x_coco/mask_rcnn_r50_fpn_carafe_1x_coco_bbox_mAP-0.393__segm_mAP-0.358_20200503_135957-8687f195.pth\"\n",
        "model_name=\"mask_rcnn_r50_fpn_carafe_1x_coco_mask_rcnn_r50_fpn_carafe_1x_coco_bbox_mAP-0.393__segm_mAP-0.358_20200503_135957-8687f195\"\n",
        "\"/content/mmdetection/configs/carafe/mask_rcnn_r50_fpn_carafe_1x_coco.py\"\n",
        "\n",
        "# gn+ws\n",
        "link=\"https://download.openmmlab.com/mmdetection/v2.0/gn%2Bws/mask_rcnn_r50_fpn_gn_ws-all_2x_coco/mask_rcnn_r50_fpn_gn_ws-all_2x_coco_20200226-16acb762.pth\"\n",
        "model_name=\"mask_rcnn_r50_fpn_gn_ws-all_2x_coco_mask_rcnn_r50_fpn_gn_ws-all_2x_coco_20200226-16acb762\"\n",
        "\"/content/mmdetection/configs/gn+ws/mask_rcnn_r50_fpn_gn_ws-all_2x_coco.py\"\n",
        "\n",
        "# pointrend\n",
        "link=\"https://download.openmmlab.com/mmdetection/v2.0/point_rend/point_rend_r50_caffe_fpn_mstrain_3x_coco/point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7.pth\"\n",
        "model_name=\"point_rend_r50_caffe_fpn_mstrain_3x_coco_point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7\"\n",
        "\"/content/mmdetection/configs/point_rend/point_rend_r50_caffe_fpn_mstrain_3x_coco.py\"\n",
        "\n",
        "# scratch\n",
        "link=\"https://download.openmmlab.com/mmdetection/v2.0/scratch/mask_rcnn_r50_fpn_gn-all_scratch_6x_coco/scratch_mask_rcnn_r50_fpn_gn_6x_bbox_mAP-0.412__segm_mAP-0.374_20200201_193051-1e190a40.pth\"\n",
        "model_name=\"mask_rcnn_r50_fpn_gn-all_scratch_6x_coco_scratch_mask_rcnn_r50_fpn_gn_6x_bbox_mAP-0.412__segm_mAP-0.374_20200201_193051-1e190a40\"\n",
        "\"/content/mmdetection/configs/scratch/mask_rcnn_r50_fpn_gn-all_scratch_6x_coco.py\"\n",
        "\n",
        "# solov2 light r18\n",
        "link=\"https://download.openmmlab.com/mmdetection/v2.0/solov2/solov2_light_r18_fpn_3x_coco/solov2_light_r18_fpn_3x_coco_20220511_083717-75fa355b.pth\"\n",
        "model_name=\"solov2_light_r18_fpn_3x_coco_solov2_light_r18_fpn_3x_coco_20220511_083717-75fa355b\"\n",
        "\"/content/mmdetection/configs/solov2/solov2_light_r18_fpn_3x_coco.py\"\n",
        "\n",
        "# yolact\n",
        "link=\"https://download.openmmlab.com/mmdetection/v2.0/yolact/yolact_r50_8x8_coco/yolact_r50_8x8_coco_20200908-ca34f5db.pth\"\n",
        "model_name=\"yolact_r50_8x8_coco_yolact_r50_8x8_coco_20200908-ca34f5db\"\n",
        "\"/content/mmdetection/configs/yolact/yolact_r50_8x8_coco.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K7NcA3PgZfuL",
        "outputId": "ed65bc47-22ca-4091-eccc-e7fe282b0996"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mmdetection/configs/yolact/yolact_r50_8x8_coco.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DOWNLOAD MODEL WEIGHTS"
      ],
      "metadata": {
        "id": "WPzQNFvC-Ptx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/model_weights\n",
        "\n",
        "link=\"https://download.openmmlab.com/mmdetection/v2.0/point_rend/point_rend_r50_caffe_fpn_mstrain_3x_coco/point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7.pth\"\n",
        "model_name=\"point_rend_r50_caffe_fpn_mstrain_3x_coco_point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7\"\n",
        "\n",
        "file_name=\"/content/model_weights\"\n",
        "!wget -c \"{link}\" -O \"{file_name}/{model_name}.pth\"  "
      ],
      "metadata": {
        "id": "w1pYIK5VRUra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "wmG4KRXuNFAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTING DEPENDENCIES"
      ],
      "metadata": {
        "id": "v3XHwcw43wiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mmcv\n",
        "from mmcv import Config\n",
        "from mmdet.apis import set_random_seed\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "from mmdet.utils import get_device\n",
        "from mmdet.apis import inference_detector, show_result_pyplot"
      ],
      "metadata": {
        "id": "3mfWrde43tP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CHANGE THE CONFIG FILE \n",
        "\n",
        "* Get any model configs from this link: /content/mmdetection/configs\n"
      ],
      "metadata": {
        "id": "9gI9jludzLa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config=\"/content/mmdetection/configs/point_rend/point_rend_r50_caffe_fpn_mstrain_3x_coco.py\"\n",
        "cfg = Config.fromfile(config)\n",
        "# USE THE MODEL FILES TO TRAIN BETTER AND QUICKER\n",
        "cfg.load_from=\"/content/model_weights/point_rend_r50_caffe_fpn_mstrain_3x_coco_point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7.pth\"\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "# carafe\n",
        "# link=\"https://download.openmmlab.com/mmdetection/v2.0/carafe/mask_rcnn_r50_fpn_carafe_1x_coco/mask_rcnn_r50_fpn_carafe_1x_coco_bbox_mAP-0.393__segm_mAP-0.358_20200503_135957-8687f195.pth\"\n",
        "# model_name=\"mask_rcnn_r50_fpn_carafe_1x_coco_mask_rcnn_r50_fpn_carafe_1x_coco_bbox_mAP-0.393__segm_mAP-0.358_20200503_135957-8687f195\"\n",
        "# \"/content/mmdetection/configs/carafe/mask_rcnn_r50_fpn_carafe_1x_coco.py\"\n",
        "\n",
        "# gn+ws\n",
        "# link=\"https://download.openmmlab.com/mmdetection/v2.0/gn%2Bws/mask_rcnn_r50_fpn_gn_ws-all_2x_coco/mask_rcnn_r50_fpn_gn_ws-all_2x_coco_20200226-16acb762.pth\"\n",
        "# model_name=\"mask_rcnn_r50_fpn_gn_ws-all_2x_coco_mask_rcnn_r50_fpn_gn_ws-all_2x_coco_20200226-16acb762\"\n",
        "# \"/content/mmdetection/configs/gn+ws/mask_rcnn_r50_fpn_gn_ws-all_2x_coco.py\"\n",
        "\n",
        "# pointrend\n",
        "# link=\"https://download.openmmlab.com/mmdetection/v2.0/point_rend/point_rend_r50_caffe_fpn_mstrain_3x_coco/point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7.pth\"\n",
        "# model_name=\"point_rend_r50_caffe_fpn_mstrain_3x_coco_point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7\"\n",
        "# \"/content/mmdetection/configs/point_rend/point_rend_r50_caffe_fpn_mstrain_3x_coco.py\"\n",
        "\n",
        "# scratch\n",
        "# link=\"https://download.openmmlab.com/mmdetection/v2.0/scratch/mask_rcnn_r50_fpn_gn-all_scratch_6x_coco/scratch_mask_rcnn_r50_fpn_gn_6x_bbox_mAP-0.412__segm_mAP-0.374_20200201_193051-1e190a40.pth\"\n",
        "# model_name=\"mask_rcnn_r50_fpn_gn-all_scratch_6x_coco_scratch_mask_rcnn_r50_fpn_gn_6x_bbox_mAP-0.412__segm_mAP-0.374_20200201_193051-1e190a40\"\n",
        "# \"/content/mmdetection/configs/scratch/mask_rcnn_r50_fpn_gn-all_scratch_6x_coco.py\"\n",
        "\n",
        "# solov2 light r18\n",
        "# link=\"https://download.openmmlab.com/mmdetection/v2.0/solov2/solov2_light_r18_fpn_3x_coco/solov2_light_r18_fpn_3x_coco_20220511_083717-75fa355b.pth\"\n",
        "# model_name=\"solov2_light_r18_fpn_3x_coco_solov2_light_r18_fpn_3x_coco_20220511_083717-75fa355b\"\n",
        "# \"/content/mmdetection/configs/solov2/solov2_light_r18_fpn_3x_coco.py\"\n",
        "\n",
        "# yolact\n",
        "# link=\"https://download.openmmlab.com/mmdetection/v2.0/yolact/yolact_r50_8x8_coco/yolact_r50_8x8_coco_20200908-ca34f5db.pth\"\n",
        "# model_name=\"yolact_r50_8x8_coco_yolact_r50_8x8_coco_20200908-ca34f5db\"\n",
        "# \"/content/mmdetection/configs/yolact/yolact_r50_8x8_coco.py\""
      ],
      "metadata": {
        "id": "X0nMk4Vny3MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the number of classes in box head and mask head\n",
        "# cfg.model.bbox_head.num_classes = 1\n",
        "# cfg.model.rpn_head.num_classes = 1\n",
        "cfg.model.roi_head.bbox_head.num_classes = 1\n",
        "cfg.model.roi_head.mask_head.num_classes = 1\n",
        "cfg.model.roi_head.point_head.num_classes = 1\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.optimizer.lr = 0.02 /8\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.runner.max_epochs=25\n",
        "cfg.log_config.interval = cfg.runner.max_epochs+1\n",
        "cfg.evaluation.interval = cfg.runner.max_epochs+1\n",
        "# Savepoint after mentioned intervals\n",
        "cfg.checkpoint_config.interval = 5\n",
        "cfg.device=get_device()\n",
        "\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "# set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='TensorboardLoggerHook')]\n",
        "\n",
        "\n",
        "# We can initialize the logger for training and have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ],
      "metadata": {
        "id": "RyNK7-7qCf3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DATASET AND CLASSES\n"
      ],
      "metadata": {
        "id": "v27JXg7n2MaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/cracks.zip -d /content/"
      ],
      "metadata": {
        "id": "zhD5_4Ayxasz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instaboostfast"
      ],
      "metadata": {
        "id": "A4WIIZua9X37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset-Type\n",
        "cfg.dataset_type = 'COCODataset'\n",
        "\n",
        "# Training Files and Annotations\n",
        "cfg.data.train.ann_file = '/content/cracks/train/train.json'\n",
        "cfg.data.train.img_prefix = '/content/cracks/train/images'\n",
        "cfg.data.train.classes = ('Crack',)\n",
        "\n",
        "# Testing Files and Annotations\n",
        "cfg.data.test.ann_file = '/content/cracks/test/test.json'\n",
        "cfg.data.test.img_prefix = '/content/cracks/test/images'\n",
        "cfg.data.test.classes = ('Crack',)\n",
        "\n",
        "# Validation Files and Annotations\n",
        "cfg.data.val.ann_file = '/content/cracks/test/test.json'\n",
        "cfg.data.val.img_prefix = '/content/cracks/test/images'\n",
        "cfg.data.val.classes = ('Crack',)\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]"
      ],
      "metadata": {
        "id": "Ox1XxojN2IKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIRECTORY FOR SAVING LOGS AND MODEL WEIGHTS"
      ],
      "metadata": {
        "id": "A3tlUA8LDQvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/logs_and_weights\n",
        "cfg.work_dir = '/content/logs_and_weights'\n",
        "# mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))"
      ],
      "metadata": {
        "id": "W4UXapxEDRZ1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ASSIGNING THE MODEL THE CONIG FILE"
      ],
      "metadata": {
        "id": "k99U7NsEDLfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_detector(cfg.model)\n",
        "model.CLASSES = datasets[0].CLASSES"
      ],
      "metadata": {
        "id": "P-ZcL1w8R-a-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets[0].CLASSES"
      ],
      "metadata": {
        "id": "AIOtyfPV1i9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FINALLY TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "65CMAt5qL7pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ],
      "metadata": {
        "id": "dA9O9aQdL6Ms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0f54ae-0e3b-44b6-f035-1287d1a9472e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-01-02 08:59:51,513 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
            "2023-01-02 08:59:51,526 - mmdet - INFO - load checkpoint from local path: /content/model_weights/point_rend_r50_caffe_fpn_mstrain_3x_coco_point_rend_r50_caffe_fpn_mstrain_3x_coco-e0ebb6b7.pth\n",
            "2023-01-02 08:59:51,705 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n",
            "size mismatch for roi_head.mask_head.fc_logits.weight: copying a param with shape torch.Size([3920, 1024]) from checkpoint, the shape in current model is torch.Size([49, 1024]).\n",
            "size mismatch for roi_head.mask_head.fc_logits.bias: copying a param with shape torch.Size([3920]) from checkpoint, the shape in current model is torch.Size([49]).\n",
            "size mismatch for roi_head.point_head.fcs.0.conv.weight: copying a param with shape torch.Size([256, 336, 1]) from checkpoint, the shape in current model is torch.Size([256, 257, 1]).\n",
            "size mismatch for roi_head.point_head.fcs.1.conv.weight: copying a param with shape torch.Size([256, 336, 1]) from checkpoint, the shape in current model is torch.Size([256, 257, 1]).\n",
            "size mismatch for roi_head.point_head.fcs.2.conv.weight: copying a param with shape torch.Size([256, 336, 1]) from checkpoint, the shape in current model is torch.Size([256, 257, 1]).\n",
            "size mismatch for roi_head.point_head.fc_logits.weight: copying a param with shape torch.Size([80, 336, 1]) from checkpoint, the shape in current model is torch.Size([1, 257, 1]).\n",
            "size mismatch for roi_head.point_head.fc_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "2023-01-02 08:59:51,713 - mmdet - INFO - Start running, host: root@caaeb9247a19, work_dir: /content/logs_and_weights\n",
            "2023-01-02 08:59:51,716 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) TensorboardLoggerHook              \n",
            " -------------------- \n",
            "2023-01-02 08:59:51,718 - mmdet - INFO - workflow: [('train', 1)], max: 25 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-01-02 08:59:51,722 - mmdet - INFO - Checkpoints will be saved to /content/logs_and_weights by HardDiskBackend.\n",
            "2023-01-02 09:00:29,483 - mmdet - INFO - Saving checkpoint at 5 epochs\n",
            "2023-01-02 09:00:59,223 - mmdet - INFO - Saving checkpoint at 10 epochs\n",
            "2023-01-02 09:01:28,543 - mmdet - INFO - Saving checkpoint at 15 epochs\n",
            "2023-01-02 09:01:58,139 - mmdet - INFO - Saving checkpoint at 20 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TESTING THE MODEL"
      ],
      "metadata": {
        "id": "BXudPEXHMBwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING THE MODEL\n",
        "link=\"/content/steel_crack/train/images/1-s2-0-S0013794408003500-gr5_jpg.rf.0f1c8bc6734499b16d0b76e1d100c5fc.jpg\"\n",
        "img = mmcv.imread(link)\n",
        "model.cfg = cfg\n",
        "result = inference_detector(model, img)\n",
        "show_result_pyplot(model, img, result,score_thr=0.0)"
      ],
      "metadata": {
        "id": "8wjiJXLGR_JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TENSORBOARD EVALUATIONS"
      ],
      "metadata": {
        "id": "mmANTeFx1xgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD TENSORBOARD AND SEE THE LOSS CURVES\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/logs_and_weights/tf_logs"
      ],
      "metadata": {
        "id": "O0ztn9YESRS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TESTING THE MODEL"
      ],
      "metadata": {
        "id": "h3wc5bB4-yBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "from mmdet.apis import inference_detector, show_result_pyplot\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.utils import get_device\n",
        "\n",
        "config = '/content/mmdetection/configs/point_rend/point_rend_r50_caffe_fpn_mstrain_3x_coco.py'\n",
        "cfg = mmcv.Config.fromfile(config)\n",
        "model_weight= \"/content/mmdetection/tutorial_exps/latest.pth\"\n",
        "\n",
        "# Setting up model\n",
        "model = build_detector(cfg.model)\n",
        "model_weight = load_checkpoint(model, model_weight, map_location=get_device())\n",
        "model.CLASSES = model_weight['meta']['CLASSES']\n",
        "model.cfg = cfg\n",
        "model.to(get_device())\n",
        "model.eval()\n",
        "\n",
        "print(f'Config:\\n{model_weight}')"
      ],
      "metadata": {
        "id": "buFtaCRsRYx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the detector to do inference\n",
        "img = 'demo/demo.jpg'\n",
        "result = inference_detector(model, img)\n",
        "show_result_pyplot(model, img, result, score_thr=0.0)"
      ],
      "metadata": {
        "id": "F44nAyHwRZas"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}